{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a324b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken datasets wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12296f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470b4f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416f60276bd3469985f8ac07c8b0090f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2714cf048249fe85c34b05eb3e2f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00000-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b53f13ce9048f6b624f35fceafdb2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00001-of-00015.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64d159b983d4191a74c4ead85a3c2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00002-of-00015.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30df067ff94c4ba880f55b6bb77ed0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00003-of-00015.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030a7a3d81dc4c388b1cbb105d0460dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00004-of-00015.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91807d39d4404ca2b10c9780e102057b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00005-of-00015.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db554f83425e472eb2e79a4571c50872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00006-of-00015.parquet:   0%|          | 0.00/229M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492d6fb84e9741a8830214f7d164c6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00007-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a8c391bfad4baf9773828545f9da68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00008-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947a13d203db45409b3e67b46cbddea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00009-of-00015.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1d311bdd9e4201a0bcef98db028ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00010-of-00015.parquet:   0%|          | 0.00/229M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9068a2615542f8872d05fd34e2a6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00011-of-00015.parquet:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aea75c8ca4246bb95ca875c44d4e5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00012-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d115d0ea71e443918094d55254ab501f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00013-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcf3028d31548cf8275667961c1ba32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/train-00014-of-00015.parquet:   0%|          | 0.00/235M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ad47cac80342ca9bc69173fc777086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/validation-00000-of-00001.parque(…):   0%|          | 0.00/105M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81c0c1ce3684d50ae7159ea9363b114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "section/test-00000-of-00001.parquet:   0%|          | 0.00/105M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2815b1438f047c29ec430f7671346d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/203037 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b15d6f026e54bca9fcc121e4a78b9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/6436 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe0c3710afc42728b7f8d794f6d55ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 203037 papers\n",
      "Keys: dict_keys(['article', 'abstract'])\n",
      "\n",
      "Sample abstract:\n",
      "additive models play an important role in semiparametric statistics . \n",
      " this paper gives learning rates for regularized kernel based methods for additive models . \n",
      " these learning rates compare favourably in particular in high dimensions to recent results on optimal learning rates for purely nonparametric regularized kernel based quantile regression using the gaussian radial basis function kernel , provided the assumption of an additive model is valid . \n",
      " additionally , a concrete example is pre\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load only a small slice first\n",
    "ds = load_dataset(\"ccdv/arxiv-summarization\", split=\"train[:500000]\")\n",
    "print(f\"Loaded: {len(ds)} papers\")\n",
    "print(f\"Keys: {ds[0].keys()}\")\n",
    "print(f\"\\nSample abstract:\\n{ds[0]['abstract'][:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a71ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robotics/ML papers found: 12664\n",
      "\n",
      "Sample 1:\n",
      "we report on strong enhancement of mid - infrared second harmonic generation ( shg ) from sic nanopillars due to the resonant excitation of localized surface phonon - polaritons within the reststrahlen band . \n",
      " the magnitude of the shg peak at the monopole mode experiences a strong dependence on the\n",
      "\n",
      "Sample 2:\n",
      "synaptic memory is considered to be the main element responsible for learning and cognition in humans . \n",
      " although traditionally non - volatile long - term plasticity changes have been implemented in nanoelectronic synapses for neuromorphic applications , recent studies in neuroscience have revealed\n"
     ]
    }
   ],
   "source": [
    "# Filter for robotics and ML papers\n",
    "keywords = ['robot', 'manipulation', 'reinforcement learning', \n",
    "            'policy', 'control', 'autonomous', 'transformer',\n",
    "            'neural', 'perception', 'planning']\n",
    "\n",
    "robotics_abstracts = []\n",
    "for paper in ds:\n",
    "    abstract = paper['abstract'].lower()\n",
    "    if any(kw in abstract for kw in keywords):\n",
    "        robotics_abstracts.append(paper['abstract'].strip())\n",
    "\n",
    "print(f\"Robotics/ML papers found: {len(robotics_abstracts)}\")\n",
    "print(f\"\\nSample 1:\\n{robotics_abstracts[0][:300]}\")\n",
    "print(f\"\\nSample 2:\\n{robotics_abstracts[1][:300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07251fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 66,391,959\n",
      "Estimated tokens: 16,597,989\n",
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "full_text = \"\\n\\n\".join(robotics_abstracts)\n",
    "print(f\"Total characters: {len(full_text):,}\")\n",
    "print(f\"Estimated tokens: {len(full_text)//4:,}\")\n",
    "\n",
    "with open('robotics_corpus.txt', 'w') as f:\n",
    "    f.write(full_text)\n",
    "    \n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54297941",
   "metadata": {},
   "source": [
    "## Tokeniser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5d997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7388f31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample abstract:3820 tokens\n",
      "Vocab size: 50257\n"
     ]
    }
   ],
   "source": [
    "tokens = enc.encode(robotics_abstracts[0])\n",
    "print(f\"Sample abstract:{len(tokens)} tokens\")\n",
    "print(f\"Vocab size: {enc.n_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba78e819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Whole Corpus \n",
      "Tensor shape: torch.Size([16264962])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Encoding Whole Corpus \")\n",
    "all_tokens  = enc.encode(full_text)\n",
    "\n",
    "data = torch.tensor(all_tokens, dtype=torch.long)\n",
    "print(f\"Tensor shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a55ee8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = enc.n_vocab  \n",
    "block_size = 128\n",
    "batch_size = 32\n",
    "d_model = 128\n",
    "n_heads = 4\n",
    "n_layers = 4\n",
    "dropout = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b92f3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 14,638,465 tokens\n",
      "Val:   1,626,497 tokens\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(f\"Train: {len(train_data):,} tokens\")\n",
    "print(f\"Val:   {len(val_data):,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfaf48",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77a4002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        \n",
    "    def split_head(self, x , B , T):\n",
    "            split = x.view(B, T , self.n_heads , self.d_k).transpose(1 ,2)\n",
    "            return split\n",
    "        \n",
    "        \n",
    "    def merge_heads(self , x , B , T ,C):\n",
    "            return x.transpose(1,2).contiguous().view(B, T, C)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "            B ,T , C = x.shape\n",
    "            \n",
    "            \n",
    "            Q = self.split_head(self.W_q(x) , B ,T)\n",
    "            K = self.split_head(self.W_k(x) , B ,T)\n",
    "            V = self.split_head(self.W_v(x) , B ,T)\n",
    "            \n",
    "            \n",
    "            scores = Q @ K.transpose(-2, -1)          # (B, h, T, T)\n",
    "            scores = scores / math.sqrt(self.d_k)\n",
    "            mask = torch.triu(torch.ones(T, T, device=x.device), diagonal=1).bool()\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "            attn = F.softmax(scores, dim=-1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            out = attn @ V                           \n",
    "            out = self.merge_heads(out, B, T, C)      \n",
    "\n",
    "            return self.W_o(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7523c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, 4 * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * d_model, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.dropout(self.attn(self.norm1(x)))\n",
    "        x = x + self.dropout(self.ffn(self.norm2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "726f11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TinyTransformer(nn.Module):\n",
    "    def __init__(self,vocab_size ,d_model , n_heads , max_seq_len , n_layers=2 ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "        # self.block1 = TransformerBlock(d_model, n_heads)\n",
    "        # self.block2 = TransformerBlock(d_model, n_heads)\n",
    "        self.head = nn.Linear(d_model, vocab_size)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(d_model, n_heads) for _ in range(n_layers)])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        positions = torch.arange(T, device=x.device)\n",
    "        \n",
    "        x = self.embedding(x) + self.pos_embedding(positions)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.head(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d0768ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=d_model,\n",
    "    n_heads=n_heads,\n",
    "    max_seq_len=block_size,\n",
    "    n_layers=n_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea2cca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Total parameters: 13,725,521\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9906371",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af31021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data):\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]).to(device)\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb2fe235",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b8a3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 100\n",
    "max_steps = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fff84b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(step):\n",
    "    if step < warmup_steps:\n",
    "        return step / warmup_steps \n",
    "    progress = (step - warmup_steps) / (max_steps - warmup_steps)\n",
    "    return 0.5 * (1 + math.cos(math.pi * progress)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ab0147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, get_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e63a3d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b8bd74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyTransformer(\n",
       "  (embedding): Embedding(50257, 128)\n",
       "  (pos_embedding): Embedding(128, 128)\n",
       "  (head): Linear(in_features=128, out_features=50257, bias=True)\n",
       "  (blocks): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "losses = []\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ba10c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step    0 | loss 4.3229 | lr 0.000293\n",
      "step  100 | loss 4.2232 | lr 0.000292\n",
      "step  200 | loss 4.5816 | lr 0.000292\n",
      "step  300 | loss 4.3250 | lr 0.000291\n",
      "step  400 | loss 4.5178 | lr 0.000291\n",
      "step  500 | loss 4.4010 | lr 0.000290\n",
      "  → Checkpoint saved: robotics_gpt_step500.pt\n",
      "step  600 | loss 4.1922 | lr 0.000290\n",
      "step  700 | loss 4.2426 | lr 0.000289\n",
      "step  800 | loss 4.3097 | lr 0.000288\n",
      "step  900 | loss 4.3781 | lr 0.000288\n",
      "step 1000 | loss 4.3206 | lr 0.000287\n",
      "  → Checkpoint saved: robotics_gpt_step1000.pt\n",
      "step 1100 | loss 4.2437 | lr 0.000286\n",
      "step 1200 | loss 4.3352 | lr 0.000286\n",
      "step 1300 | loss 4.4064 | lr 0.000285\n",
      "step 1400 | loss 4.0117 | lr 0.000284\n",
      "step 1500 | loss 4.1325 | lr 0.000284\n",
      "  → Checkpoint saved: robotics_gpt_step1500.pt\n",
      "step 1600 | loss 4.3920 | lr 0.000283\n",
      "step 1700 | loss 4.4113 | lr 0.000282\n",
      "step 1800 | loss 4.0190 | lr 0.000282\n",
      "step 1900 | loss 4.2043 | lr 0.000281\n",
      "step 2000 | loss 4.0763 | lr 0.000280\n",
      "  → Checkpoint saved: robotics_gpt_step2000.pt\n",
      "step 2100 | loss 4.3419 | lr 0.000279\n",
      "step 2200 | loss 4.0622 | lr 0.000278\n",
      "step 2300 | loss 4.1321 | lr 0.000278\n",
      "step 2400 | loss 4.2622 | lr 0.000277\n",
      "step 2500 | loss 4.1542 | lr 0.000276\n",
      "  → Checkpoint saved: robotics_gpt_step2500.pt\n",
      "step 2600 | loss 3.9148 | lr 0.000275\n",
      "step 2700 | loss 4.3152 | lr 0.000274\n",
      "step 2800 | loss 4.1944 | lr 0.000273\n",
      "step 2900 | loss 3.9910 | lr 0.000272\n",
      "step 3000 | loss 4.2215 | lr 0.000271\n",
      "  → Checkpoint saved: robotics_gpt_step3000.pt\n",
      "step 3100 | loss 4.0225 | lr 0.000270\n",
      "step 3200 | loss 4.1997 | lr 0.000270\n",
      "step 3300 | loss 4.1797 | lr 0.000269\n",
      "step 3400 | loss 3.7676 | lr 0.000268\n",
      "step 3500 | loss 4.2713 | lr 0.000267\n",
      "  → Checkpoint saved: robotics_gpt_step3500.pt\n",
      "step 3600 | loss 4.0906 | lr 0.000266\n",
      "step 3700 | loss 4.1271 | lr 0.000265\n",
      "step 3800 | loss 4.1755 | lr 0.000264\n",
      "step 3900 | loss 4.2562 | lr 0.000263\n",
      "step 4000 | loss 4.1823 | lr 0.000261\n",
      "  → Checkpoint saved: robotics_gpt_step4000.pt\n",
      "step 4100 | loss 3.8700 | lr 0.000260\n",
      "step 4200 | loss 4.0455 | lr 0.000259\n",
      "step 4300 | loss 3.7833 | lr 0.000258\n",
      "step 4400 | loss 4.3620 | lr 0.000257\n",
      "step 4500 | loss 3.7908 | lr 0.000256\n",
      "  → Checkpoint saved: robotics_gpt_step4500.pt\n",
      "step 4600 | loss 3.9584 | lr 0.000255\n",
      "step 4700 | loss 4.0112 | lr 0.000254\n",
      "step 4800 | loss 3.9612 | lr 0.000253\n",
      "step 4900 | loss 3.9713 | lr 0.000252\n",
      "step 5000 | loss 3.9758 | lr 0.000250\n",
      "  → Checkpoint saved: robotics_gpt_step5000.pt\n",
      "step 5100 | loss 3.8015 | lr 0.000249\n",
      "step 5200 | loss 3.8932 | lr 0.000248\n",
      "step 5300 | loss 4.0697 | lr 0.000247\n",
      "step 5400 | loss 3.9644 | lr 0.000246\n",
      "step 5500 | loss 3.7204 | lr 0.000244\n",
      "  → Checkpoint saved: robotics_gpt_step5500.pt\n",
      "step 5600 | loss 3.9686 | lr 0.000243\n",
      "step 5700 | loss 4.0721 | lr 0.000242\n",
      "step 5800 | loss 3.6726 | lr 0.000241\n",
      "step 5900 | loss 3.9175 | lr 0.000239\n",
      "step 6000 | loss 3.8795 | lr 0.000238\n",
      "  → Checkpoint saved: robotics_gpt_step6000.pt\n",
      "step 6100 | loss 3.9309 | lr 0.000237\n",
      "step 6200 | loss 4.0002 | lr 0.000236\n",
      "step 6300 | loss 3.8126 | lr 0.000234\n",
      "step 6400 | loss 3.8142 | lr 0.000233\n",
      "step 6500 | loss 3.6872 | lr 0.000232\n",
      "  → Checkpoint saved: robotics_gpt_step6500.pt\n",
      "step 6600 | loss 3.9954 | lr 0.000230\n",
      "step 6700 | loss 3.8991 | lr 0.000229\n",
      "step 6800 | loss 3.9846 | lr 0.000228\n",
      "step 6900 | loss 4.0786 | lr 0.000226\n",
      "step 7000 | loss 3.7746 | lr 0.000225\n",
      "  → Checkpoint saved: robotics_gpt_step7000.pt\n",
      "step 7100 | loss 3.2982 | lr 0.000224\n",
      "step 7200 | loss 3.7619 | lr 0.000222\n",
      "step 7300 | loss 3.9047 | lr 0.000221\n",
      "step 7400 | loss 3.7774 | lr 0.000219\n",
      "step 7500 | loss 3.7252 | lr 0.000218\n",
      "  → Checkpoint saved: robotics_gpt_step7500.pt\n",
      "step 7600 | loss 3.7647 | lr 0.000217\n",
      "step 7700 | loss 3.8574 | lr 0.000215\n",
      "step 7800 | loss 3.8188 | lr 0.000214\n",
      "step 7900 | loss 3.7383 | lr 0.000212\n",
      "step 8000 | loss 3.8016 | lr 0.000211\n",
      "  → Checkpoint saved: robotics_gpt_step8000.pt\n",
      "step 8100 | loss 3.8696 | lr 0.000209\n",
      "step 8200 | loss 3.7058 | lr 0.000208\n",
      "step 8300 | loss 3.7821 | lr 0.000207\n",
      "step 8400 | loss 3.7259 | lr 0.000205\n",
      "step 8500 | loss 3.9035 | lr 0.000204\n",
      "  → Checkpoint saved: robotics_gpt_step8500.pt\n",
      "step 8600 | loss 3.8410 | lr 0.000202\n",
      "step 8700 | loss 3.7930 | lr 0.000201\n",
      "step 8800 | loss 3.9689 | lr 0.000199\n",
      "step 8900 | loss 3.5623 | lr 0.000198\n",
      "step 9000 | loss 3.8900 | lr 0.000196\n",
      "  → Checkpoint saved: robotics_gpt_step9000.pt\n",
      "step 9100 | loss 3.6107 | lr 0.000195\n",
      "step 9200 | loss 3.7046 | lr 0.000193\n",
      "step 9300 | loss 3.8313 | lr 0.000192\n",
      "step 9400 | loss 3.7351 | lr 0.000190\n",
      "step 9500 | loss 3.7259 | lr 0.000189\n",
      "  → Checkpoint saved: robotics_gpt_step9500.pt\n",
      "step 9600 | loss 3.5838 | lr 0.000187\n",
      "step 9700 | loss 3.6999 | lr 0.000186\n",
      "step 9800 | loss 3.6444 | lr 0.000184\n",
      "step 9900 | loss 3.7111 | lr 0.000182\n",
      "step 10000 | loss 3.7210 | lr 0.000181\n",
      "  → Checkpoint saved: robotics_gpt_step10000.pt\n",
      "step 10100 | loss 3.6077 | lr 0.000179\n",
      "step 10200 | loss 3.8204 | lr 0.000178\n",
      "step 10300 | loss 3.6880 | lr 0.000176\n",
      "step 10400 | loss 3.5821 | lr 0.000175\n",
      "step 10500 | loss 3.5366 | lr 0.000173\n",
      "  → Checkpoint saved: robotics_gpt_step10500.pt\n",
      "step 10600 | loss 3.4651 | lr 0.000172\n",
      "step 10700 | loss 3.6596 | lr 0.000170\n",
      "step 10800 | loss 3.7473 | lr 0.000168\n",
      "step 10900 | loss 3.6700 | lr 0.000167\n",
      "step 11000 | loss 3.9149 | lr 0.000165\n",
      "  → Checkpoint saved: robotics_gpt_step11000.pt\n",
      "step 11100 | loss 3.3968 | lr 0.000164\n",
      "step 11200 | loss 3.4715 | lr 0.000162\n",
      "step 11300 | loss 3.5993 | lr 0.000161\n",
      "step 11400 | loss 4.0258 | lr 0.000159\n",
      "step 11500 | loss 3.6290 | lr 0.000157\n",
      "  → Checkpoint saved: robotics_gpt_step11500.pt\n",
      "step 11600 | loss 3.9853 | lr 0.000156\n",
      "step 11700 | loss 3.6836 | lr 0.000154\n",
      "step 11800 | loss 3.6401 | lr 0.000153\n",
      "step 11900 | loss 3.7481 | lr 0.000151\n",
      "step 12000 | loss 3.6362 | lr 0.000150\n",
      "  → Checkpoint saved: robotics_gpt_step12000.pt\n",
      "step 12100 | loss 3.5203 | lr 0.000148\n",
      "step 12200 | loss 3.6678 | lr 0.000146\n",
      "step 12300 | loss 3.5225 | lr 0.000145\n",
      "step 12400 | loss 3.7481 | lr 0.000143\n",
      "step 12500 | loss 3.6875 | lr 0.000142\n",
      "  → Checkpoint saved: robotics_gpt_step12500.pt\n",
      "step 12600 | loss 3.5376 | lr 0.000140\n",
      "step 12700 | loss 3.6371 | lr 0.000139\n",
      "step 12800 | loss 3.6743 | lr 0.000137\n",
      "step 12900 | loss 3.7519 | lr 0.000135\n",
      "step 13000 | loss 3.5309 | lr 0.000134\n",
      "  → Checkpoint saved: robotics_gpt_step13000.pt\n",
      "step 13100 | loss 3.7232 | lr 0.000132\n",
      "step 13200 | loss 3.8603 | lr 0.000131\n",
      "step 13300 | loss 3.4343 | lr 0.000129\n",
      "step 13400 | loss 3.6592 | lr 0.000128\n",
      "step 13500 | loss 3.4119 | lr 0.000126\n",
      "  → Checkpoint saved: robotics_gpt_step13500.pt\n",
      "step 13600 | loss 3.4876 | lr 0.000125\n",
      "step 13700 | loss 3.3711 | lr 0.000123\n",
      "step 13800 | loss 3.4999 | lr 0.000121\n",
      "step 13900 | loss 3.9552 | lr 0.000120\n",
      "step 14000 | loss 3.5906 | lr 0.000118\n",
      "  → Checkpoint saved: robotics_gpt_step14000.pt\n",
      "step 14100 | loss 3.9114 | lr 0.000117\n",
      "step 14200 | loss 3.6308 | lr 0.000115\n",
      "step 14300 | loss 3.6783 | lr 0.000114\n",
      "step 14400 | loss 3.5022 | lr 0.000112\n",
      "step 14500 | loss 3.7632 | lr 0.000111\n",
      "  → Checkpoint saved: robotics_gpt_step14500.pt\n",
      "step 14600 | loss 3.4226 | lr 0.000109\n",
      "step 14700 | loss 3.7447 | lr 0.000108\n",
      "step 14800 | loss 3.6172 | lr 0.000106\n",
      "step 14900 | loss 3.7037 | lr 0.000105\n",
      "step 15000 | loss 3.5942 | lr 0.000103\n",
      "  → Checkpoint saved: robotics_gpt_step15000.pt\n",
      "step 15100 | loss 3.5424 | lr 0.000102\n",
      "step 15200 | loss 3.7381 | lr 0.000100\n",
      "step 15300 | loss 3.4452 | lr 0.000099\n",
      "step 15400 | loss 3.7902 | lr 0.000097\n",
      "step 15500 | loss 3.7295 | lr 0.000096\n",
      "  → Checkpoint saved: robotics_gpt_step15500.pt\n",
      "step 15600 | loss 3.7335 | lr 0.000094\n",
      "step 15700 | loss 3.5334 | lr 0.000093\n",
      "step 15800 | loss 3.7387 | lr 0.000091\n",
      "step 15900 | loss 3.7115 | lr 0.000090\n",
      "step 16000 | loss 3.4189 | lr 0.000088\n",
      "  → Checkpoint saved: robotics_gpt_step16000.pt\n",
      "step 16100 | loss 3.6629 | lr 0.000087\n",
      "step 16200 | loss 3.7331 | lr 0.000086\n",
      "step 16300 | loss 3.5880 | lr 0.000084\n",
      "step 16400 | loss 3.5158 | lr 0.000083\n",
      "step 16500 | loss 3.8827 | lr 0.000081\n",
      "  → Checkpoint saved: robotics_gpt_step16500.pt\n",
      "step 16600 | loss 3.6408 | lr 0.000080\n",
      "step 16700 | loss 3.8247 | lr 0.000079\n",
      "step 16800 | loss 3.6494 | lr 0.000077\n",
      "step 16900 | loss 3.3612 | lr 0.000076\n",
      "step 17000 | loss 3.7793 | lr 0.000074\n",
      "  → Checkpoint saved: robotics_gpt_step17000.pt\n",
      "step 17100 | loss 3.5995 | lr 0.000073\n",
      "step 17200 | loss 3.5384 | lr 0.000072\n",
      "step 17300 | loss 3.3756 | lr 0.000070\n",
      "step 17400 | loss 3.8415 | lr 0.000069\n",
      "step 17500 | loss 3.4868 | lr 0.000068\n",
      "  → Checkpoint saved: robotics_gpt_step17500.pt\n",
      "step 17600 | loss 3.6213 | lr 0.000066\n",
      "step 17700 | loss 3.6092 | lr 0.000065\n",
      "step 17800 | loss 3.7384 | lr 0.000064\n",
      "step 17900 | loss 3.6872 | lr 0.000063\n",
      "step 18000 | loss 3.5245 | lr 0.000061\n",
      "  → Checkpoint saved: robotics_gpt_step18000.pt\n",
      "step 18100 | loss 3.6026 | lr 0.000060\n",
      "step 18200 | loss 3.4036 | lr 0.000059\n",
      "step 18300 | loss 3.5624 | lr 0.000058\n",
      "step 18400 | loss 3.7493 | lr 0.000056\n",
      "step 18500 | loss 3.6614 | lr 0.000055\n",
      "  → Checkpoint saved: robotics_gpt_step18500.pt\n",
      "step 18600 | loss 3.6513 | lr 0.000054\n",
      "step 18700 | loss 3.6417 | lr 0.000053\n",
      "step 18800 | loss 3.5668 | lr 0.000051\n",
      "step 18900 | loss 3.5799 | lr 0.000050\n",
      "step 19000 | loss 3.6530 | lr 0.000049\n",
      "  → Checkpoint saved: robotics_gpt_step19000.pt\n",
      "step 19100 | loss 3.6786 | lr 0.000048\n",
      "step 19200 | loss 3.7326 | lr 0.000047\n",
      "step 19300 | loss 3.5204 | lr 0.000046\n",
      "step 19400 | loss 3.7049 | lr 0.000045\n",
      "step 19500 | loss 3.3399 | lr 0.000043\n",
      "  → Checkpoint saved: robotics_gpt_step19500.pt\n",
      "step 19600 | loss 3.7294 | lr 0.000042\n",
      "step 19700 | loss 3.6727 | lr 0.000041\n",
      "step 19800 | loss 3.6300 | lr 0.000040\n",
      "step 19900 | loss 3.5097 | lr 0.000039\n",
      "step 20000 | loss 3.8535 | lr 0.000038\n",
      "  → Checkpoint saved: robotics_gpt_step20000.pt\n",
      "step 20100 | loss 3.7209 | lr 0.000037\n",
      "step 20200 | loss 3.8825 | lr 0.000036\n",
      "step 20300 | loss 3.7514 | lr 0.000035\n",
      "step 20400 | loss 3.7182 | lr 0.000034\n",
      "step 20500 | loss 3.4835 | lr 0.000033\n",
      "  → Checkpoint saved: robotics_gpt_step20500.pt\n",
      "step 20600 | loss 3.6084 | lr 0.000032\n",
      "step 20700 | loss 3.8090 | lr 0.000031\n",
      "step 20800 | loss 3.4147 | lr 0.000030\n",
      "step 20900 | loss 3.8081 | lr 0.000029\n",
      "step 21000 | loss 3.6997 | lr 0.000028\n",
      "  → Checkpoint saved: robotics_gpt_step21000.pt\n",
      "step 21100 | loss 3.6782 | lr 0.000027\n",
      "step 21200 | loss 3.2708 | lr 0.000026\n",
      "step 21300 | loss 3.9262 | lr 0.000025\n",
      "step 21400 | loss 3.5511 | lr 0.000025\n",
      "step 21500 | loss 3.8865 | lr 0.000024\n",
      "  → Checkpoint saved: robotics_gpt_step21500.pt\n",
      "step 21600 | loss 3.4093 | lr 0.000023\n",
      "step 21700 | loss 3.6928 | lr 0.000022\n",
      "step 21800 | loss 3.6434 | lr 0.000021\n",
      "step 21900 | loss 3.8684 | lr 0.000020\n",
      "step 22000 | loss 3.8035 | lr 0.000020\n",
      "  → Checkpoint saved: robotics_gpt_step22000.pt\n",
      "step 22100 | loss 3.6598 | lr 0.000019\n",
      "step 22200 | loss 3.4817 | lr 0.000018\n",
      "step 22300 | loss 3.6413 | lr 0.000017\n",
      "step 22400 | loss 3.6531 | lr 0.000017\n",
      "step 22500 | loss 3.6793 | lr 0.000016\n",
      "  → Checkpoint saved: robotics_gpt_step22500.pt\n",
      "step 22600 | loss 3.4976 | lr 0.000015\n",
      "step 22700 | loss 3.5159 | lr 0.000015\n",
      "step 22800 | loss 3.8234 | lr 0.000014\n",
      "step 22900 | loss 3.4826 | lr 0.000013\n",
      "step 23000 | loss 3.4859 | lr 0.000013\n",
      "  → Checkpoint saved: robotics_gpt_step23000.pt\n",
      "step 23100 | loss 3.6345 | lr 0.000012\n",
      "step 23200 | loss 3.6811 | lr 0.000011\n",
      "step 23300 | loss 3.5215 | lr 0.000011\n",
      "step 23400 | loss 3.4704 | lr 0.000010\n",
      "step 23500 | loss 3.5758 | lr 0.000010\n",
      "  → Checkpoint saved: robotics_gpt_step23500.pt\n",
      "step 23600 | loss 3.7365 | lr 0.000009\n",
      "step 23700 | loss 3.6874 | lr 0.000009\n",
      "step 23800 | loss 3.5274 | lr 0.000008\n",
      "step 23900 | loss 3.2581 | lr 0.000008\n",
      "step 24000 | loss 3.7523 | lr 0.000007\n",
      "  → Checkpoint saved: robotics_gpt_step24000.pt\n",
      "step 24100 | loss 3.2988 | lr 0.000007\n",
      "step 24200 | loss 3.5913 | lr 0.000006\n",
      "step 24300 | loss 3.6181 | lr 0.000006\n",
      "step 24400 | loss 3.7317 | lr 0.000005\n",
      "step 24500 | loss 3.4728 | lr 0.000005\n",
      "  → Checkpoint saved: robotics_gpt_step24500.pt\n",
      "step 24600 | loss 3.8666 | lr 0.000004\n",
      "step 24700 | loss 3.5197 | lr 0.000004\n",
      "step 24800 | loss 3.6500 | lr 0.000004\n",
      "step 24900 | loss 3.7235 | lr 0.000003\n",
      "step 25000 | loss 3.7203 | lr 0.000003\n",
      "  → Checkpoint saved: robotics_gpt_step25000.pt\n",
      "step 25100 | loss 3.7566 | lr 0.000003\n",
      "step 25200 | loss 3.6498 | lr 0.000002\n",
      "step 25300 | loss 3.8956 | lr 0.000002\n",
      "step 25400 | loss 3.5214 | lr 0.000002\n",
      "step 25500 | loss 3.4524 | lr 0.000002\n",
      "  → Checkpoint saved: robotics_gpt_step25500.pt\n",
      "step 25600 | loss 3.6951 | lr 0.000001\n",
      "step 25700 | loss 3.8008 | lr 0.000001\n",
      "step 25800 | loss 3.7631 | lr 0.000001\n",
      "step 25900 | loss 3.8405 | lr 0.000001\n",
      "step 26000 | loss 3.4971 | lr 0.000001\n",
      "  → Checkpoint saved: robotics_gpt_step26000.pt\n",
      "step 26100 | loss 3.6439 | lr 0.000001\n",
      "step 26200 | loss 3.7635 | lr 0.000000\n",
      "step 26300 | loss 3.4701 | lr 0.000000\n",
      "step 26400 | loss 3.5672 | lr 0.000000\n",
      "step 26500 | loss 3.2707 | lr 0.000000\n",
      "  → Checkpoint saved: robotics_gpt_step26500.pt\n",
      "step 26600 | loss 3.7465 | lr 0.000000\n",
      "step 26700 | loss 3.4802 | lr 0.000000\n",
      "step 26800 | loss 3.5432 | lr 0.000000\n",
      "step 26900 | loss 3.5269 | lr 0.000000\n",
      "step 27000 | loss 3.7267 | lr 0.000000\n",
      "  → Checkpoint saved: robotics_gpt_step27000.pt\n",
      "step 27100 | loss 3.5482 | lr 0.000000\n",
      "step 27200 | loss 3.4680 | lr 0.000000\n",
      "step 27300 | loss 3.2975 | lr 0.000000\n",
      "step 27400 | loss 3.4924 | lr 0.000000\n",
      "step 27500 | loss 3.6980 | lr 0.000000\n",
      "  → Checkpoint saved: robotics_gpt_step27500.pt\n",
      "step 27600 | loss 3.4681 | lr 0.000000\n",
      "step 27700 | loss 3.2879 | lr 0.000000\n",
      "step 27800 | loss 3.5105 | lr 0.000001\n",
      "step 27900 | loss 3.6055 | lr 0.000001\n",
      "step 28000 | loss 3.6388 | lr 0.000001\n",
      "  → Checkpoint saved: robotics_gpt_step28000.pt\n",
      "step 28100 | loss 3.3352 | lr 0.000001\n",
      "step 28200 | loss 3.6703 | lr 0.000001\n",
      "step 28300 | loss 3.5812 | lr 0.000002\n",
      "step 28400 | loss 3.5133 | lr 0.000002\n",
      "step 28500 | loss 3.3189 | lr 0.000002\n",
      "  → Checkpoint saved: robotics_gpt_step28500.pt\n",
      "step 28600 | loss 3.4986 | lr 0.000002\n",
      "step 28700 | loss 3.5248 | lr 0.000003\n",
      "step 28800 | loss 3.4459 | lr 0.000003\n",
      "step 28900 | loss 3.7377 | lr 0.000003\n",
      "step 29000 | loss 3.6480 | lr 0.000004\n",
      "  → Checkpoint saved: robotics_gpt_step29000.pt\n",
      "step 29100 | loss 3.4995 | lr 0.000004\n",
      "step 29200 | loss 3.6342 | lr 0.000004\n",
      "step 29300 | loss 3.7229 | lr 0.000005\n",
      "step 29400 | loss 3.7567 | lr 0.000005\n",
      "step 29500 | loss 3.4932 | lr 0.000005\n",
      "  → Checkpoint saved: robotics_gpt_step29500.pt\n",
      "step 29600 | loss 3.4886 | lr 0.000006\n",
      "step 29700 | loss 3.4806 | lr 0.000006\n",
      "step 29800 | loss 3.3572 | lr 0.000007\n",
      "step 29900 | loss 3.4578 | lr 0.000007\n",
      "Final model saved!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for step in range(max_steps):\n",
    "    x, y = get_batch(train_data)\n",
    "    logits = model(x)\n",
    "    loss = loss_fn(logits.transpose(1, 2), y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"step {step:4d} | loss {loss.item():.4f} | lr {lr:.6f}\")\n",
    "    \n",
    "    if step % 500 == 0 and step > 0:\n",
    "        checkpoint = {\n",
    "            'step': step,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            'config': {\n",
    "                'vocab_size': vocab_size,\n",
    "                'd_model': d_model,\n",
    "                'n_heads': n_heads,\n",
    "                'n_layers': n_layers,\n",
    "                'block_size': block_size,\n",
    "            }\n",
    "        }\n",
    "        torch.save(checkpoint, f'robotics_gpt_step{step}.pt')\n",
    "        print(f\"  → Checkpoint saved: robotics_gpt_step{step}.pt\")\n",
    "\n",
    "final_checkpoint = {\n",
    "    'step': max_steps,\n",
    "    'model_state': model.state_dict(),\n",
    "    'optimizer_state': optimizer.state_dict(),\n",
    "    'loss': losses[-1] if losses else None,\n",
    "    'config': {\n",
    "        'vocab_size': vocab_size,\n",
    "        'd_model': d_model,\n",
    "        'n_heads': n_heads,\n",
    "        'n_layers': n_layers,\n",
    "        'block_size': block_size,\n",
    "    }\n",
    "}\n",
    "torch.save(final_checkpoint, 'robotics_gpt_final.pt')\n",
    "print(\"Final model saved!\")\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "467ca461",
   "metadata": {},
   "outputs": [
    {
     "ename": "MessageError",
     "evalue": "Failed to issue request POST https://colab.research.google.com/tun/m/credentials-propagation/gpu-t4-s-34oh5b018j4if?authtype=dfs_ephemeral&version=2&dryrun=false&propagate=true&record=false&authuser=0&authuser=0: Bad Request\nResponse body: \n<!DOCTYPE html>\n<html lang=en>\n  <meta charset=utf-8>\n  <meta name=viewport content=\"initial-scale=1, minimum-scale=1, width=device-width\">\n  <title>Error 400 (Bad Request)!!1</title>\n  <style>\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n  </style>\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n  <p><b>400.</b> <ins>That’s an error.</ins>\n  <p>  <ins>That’s all we know.</ins>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1016/1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: Failed to issue request POST https://colab.research.google.com/tun/m/credentials-propagation/gpu-t4-s-34oh5b018j4if?authtype=dfs_ephemeral&version=2&dryrun=false&propagate=true&record=false&authuser=0&authuser=0: Bad Request\nResponse body: \n<!DOCTYPE html>\n<html lang=en>\n  <meta charset=utf-8>\n  <meta name=viewport content=\"initial-scale=1, minimum-scale=1, width=device-width\">\n  <title>Error 400 (Bad Request)!!1</title>\n  <style>\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n  </style>\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n  <p><b>400.</b> <ins>That’s an error.</ins>\n  <p>  <ins>That’s all we know.</ins>\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f7eb5",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d33aaf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"TinyTransformer training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c306522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(f\"Model saved at: {os.path.abspath('robotics_gpt_final.pt')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade82720",
   "metadata": {},
   "source": [
    "## Inferance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32673efb",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "\n",
    "def generate(prompt, max_new_tokens=200, temperature=0.8):\n",
    "    tokens = enc.encode(prompt)\n",
    "    idx = torch.tensor([tokens], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits = model(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, next_token], dim=1)\n",
    "    \n",
    "    return enc.decode(idx[0].tolist())\n",
    "\n",
    "print(generate(\"We propose a novel approach to robot manipulation using\"))\n",
    "print(\"---\")\n",
    "print(generate(\"In this paper we present a transformer-based policy for\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee275fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: We propose a novel method for robot grasping using \n",
      "reinforcement learning. Our approach achieves 95% success rate.\n",
      "\n",
      "Abstract:0 and their impact in good agreement with the data . \n",
      " a numerical analysis is provided by the results of the results of the framework of the education of the analysis of the physics of the european commission , and the research office for publication .\n",
      "\n",
      "we present an accurate problem in the framework of the analysis of the model of the annulated classification of the stochastic networks . \n",
      " we present a new model to study the algorithm and find a prior - controlled discrete ( les - synchrony ) solution that is currently accessible to the medium of a few - color layer ( i.e. @xmath0 ) . \n",
      " the nn is the atom - defocusing of the hop - ionized - fermion coupling at the lowest energy , and this feature is further @xcite . \n",
      " using the epsrc at half of the rate of the gas with the center of the nucleon and the dashed line is positive , which is a tight - binding energy at\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Abstract: We propose a novel method for robot grasping using \n",
    "reinforcement learning. Our approach achieves 95% success rate.\n",
    "\n",
    "Abstract:\"\"\"\n",
    "\n",
    "print(generate(prompt, temperature=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea4395",
   "metadata": {},
   "source": [
    "## Save Model To Drive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84dd8f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We propose a novel approach to robot manipulation using a coupled line sensing function whose orientation of the network . in the input laser to the node , \n",
      " further , we ask the average time of a narrow bonds , which is presented in our design , as discussed above . \n",
      " furthermore , we assume a number of inputs on a superposition of a single photons in which the nodes can be selected using a classical computer architecture . \n",
      " , we consider an example of the minimal pair of qubit states to produce the maximum entanglement and pair information in the presence of hard - mechanical interactions . \n",
      " the random variable of the quantum qd model is a robust system with a two - body interactions between the time - independent qubit and qubit states . for all qubits \n",
      " , we consider a basis by the hamiltonian @xmath39 and a separate simple coupling between intra qubits . in this , \n",
      " stabilizing the quantum resource of the entanglement entropy on the classical entanglement process , not simply only one\n",
      "---\n",
      "In this paper we present a transformer-based policy for finding complexity structure , claus of a theory of quantum algorithms for rydberg states . \n",
      " we consider the physical realization of quantum properties in two - dimensional quantum systems so and controllable , non - classical simulations in quantum mechanics . \n",
      " a recent proposal of recent study of single qubit - entangled state in quantum systems can be used as spin systems @xcite and can be described by the single - photon qhc - storage operation . \n",
      " _ acknowledgements _ \n",
      " phys . \n",
      " rev . \n",
      " lett . \n",
      " _ * 105 * , 24600 ( 2004 ) . \n",
      " m. aid and r.  kimura , a.  and d.  j. phys . \n",
      " chem . \n",
      " usa , physica b . \n",
      " rev . \n",
      " lett . \n",
      " * 1 * , # 1 ( 1971 ) . \n",
      " _ et al . \n",
      " _ phys . \n",
      " rev . \n",
      " lett . \n",
      " *\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "def generate(prompt, max_new_tokens=200, temperature=0.8):\n",
    "    tokens = enc.encode(prompt)\n",
    "    idx = torch.tensor([tokens], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits = model(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, next_token], dim=1)\n",
    "    \n",
    "    return enc.decode(idx[0].tolist())\n",
    "\n",
    "print(generate(\"We propose a novel approach to robot manipulation using\"))\n",
    "print(\"---\")\n",
    "print(generate(\"In this paper we present a transformer-based policy for\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55ae526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Model saved to Google Drive at: /content/drive/MyDrive/robotics_gpt/robotics_gpt_final.pt\n",
      "  → Also saved: robotics_gpt_step20500.pt\n",
      "  → Also saved: robotics_gpt_step21500.pt\n",
      "  → Also saved: robotics_gpt_step3000.pt\n",
      "  → Also saved: robotics_gpt_step7500.pt\n",
      "  → Also saved: robotics_gpt_step2500.pt\n",
      "  → Also saved: robotics_gpt_step7000.pt\n",
      "  → Also saved: robotics_gpt_step11500.pt\n",
      "  → Also saved: robotics_gpt_step1500.pt\n",
      "  → Also saved: robotics_gpt_step27000.pt\n",
      "  → Also saved: robotics_gpt_step1000.pt\n",
      "  → Also saved: robotics_gpt_step23500.pt\n",
      "  → Also saved: robotics_gpt_step24500.pt\n",
      "  → Also saved: robotics_gpt_step29000.pt\n",
      "  → Also saved: robotics_gpt_step22000.pt\n",
      "  → Also saved: robotics_gpt_step2000.pt\n",
      "  → Also saved: robotics_gpt_step11000.pt\n",
      "  → Also saved: robotics_gpt_step5500.pt\n",
      "  → Also saved: robotics_gpt_step21000.pt\n",
      "  → Also saved: robotics_gpt_step14000.pt\n",
      "  → Also saved: robotics_gpt_step24000.pt\n",
      "  → Also saved: robotics_gpt_step12500.pt\n",
      "  → Also saved: robotics_gpt_step9000.pt\n",
      "  → Also saved: robotics_gpt_step13500.pt\n",
      "  → Also saved: robotics_gpt_step18000.pt\n",
      "  → Also saved: robotics_gpt_step22500.pt\n",
      "  → Also saved: robotics_gpt_step20000.pt\n",
      "  → Also saved: robotics_gpt_step16500.pt\n",
      "  → Also saved: robotics_gpt_step27500.pt\n",
      "  → Also saved: robotics_gpt_step14500.pt\n",
      "  → Also saved: robotics_gpt_step23000.pt\n",
      "  → Also saved: robotics_gpt_step8500.pt\n",
      "  → Also saved: robotics_gpt_step29500.pt\n",
      "  → Also saved: robotics_gpt_step8000.pt\n",
      "  → Also saved: robotics_gpt_step6000.pt\n",
      "  → Also saved: robotics_gpt_step10500.pt\n",
      "  → Also saved: robotics_gpt_step500.pt\n",
      "  → Also saved: robotics_gpt_step4500.pt\n",
      "  → Also saved: robotics_gpt_step9500.pt\n",
      "  → Also saved: robotics_gpt_step15500.pt\n",
      "  → Also saved: robotics_gpt_step17000.pt\n",
      "  → Also saved: robotics_gpt_step18500.pt\n",
      "  → Also saved: robotics_gpt_step28000.pt\n",
      "  → Also saved: robotics_gpt_step25500.pt\n",
      "  → Also saved: robotics_gpt_step6500.pt\n",
      "  → Also saved: robotics_gpt_step19500.pt\n",
      "  → Also saved: robotics_gpt_step26000.pt\n",
      "  → Also saved: robotics_gpt_step10000.pt\n",
      "  → Also saved: robotics_gpt_step13000.pt\n",
      "  → Also saved: robotics_gpt_step17500.pt\n",
      "  → Also saved: robotics_gpt_step26500.pt\n",
      "  → Also saved: robotics_gpt_step5000.pt\n",
      "  → Also saved: robotics_gpt_step3500.pt\n",
      "  → Also saved: robotics_gpt_step25000.pt\n",
      "  → Also saved: robotics_gpt_step19000.pt\n",
      "  → Also saved: robotics_gpt_step28500.pt\n",
      "  → Also saved: robotics_gpt_step15000.pt\n",
      "  → Also saved: robotics_gpt_step4000.pt\n",
      "  → Also saved: robotics_gpt_step12000.pt\n",
      "  → Also saved: robotics_gpt_step16000.pt\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create a folder in Drive to store the model\n",
    "save_dir = '/content/drive/MyDrive/robotics_gpt'\n",
    "import os\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Copy the final model checkpoint to Drive\n",
    "shutil.copy('robotics_gpt_final.pt', f'{save_dir}/robotics_gpt_final.pt')\n",
    "print(f\"Model saved to Google Drive at: {save_dir}/robotics_gpt_final.pt\")\n",
    "\n",
    "# Also copy any periodic checkpoints if they exist\n",
    "for f in os.listdir('.'):\n",
    "    if f.startswith('robotics_gpt_step') and f.endswith('.pt'):\n",
    "        shutil.copy(f, f'{save_dir}/{f}')\n",
    "        print(f\"  → Also saved: {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f68ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
